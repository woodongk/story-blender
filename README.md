## seq2seq ëª¨ë¸ì„ ì ìš©ì‹œí‚¨ ìŠ¤í† ë¦¬ ë¬¸ì¥ ìƒì„± ì—°êµ¬
- ï¸Human-Like Story Generation from Caption Using Seq2Seq Model ( ğŸ¤– machine-like â¡ï¸ ğŸ§‘ human-like )
- 2018ë…„ë„ ì•„ì£¼ëŒ€í•™êµ ë¯¸ë””ì–´í•™ê³¼ ì¡¸ì—… í”„ë¡œì íŠ¸ ìµœìš°ìˆ˜ìƒ ìˆ˜ìƒ 

```bash
"the fireworks are shooting off in the sky" -> [Seq2Seq model] -> "the fireworks were beautiful"
```
---

## Requirement
- tensorflow 2.2.0
- keras 2.4.3
---

### í”„ë¡œì íŠ¸ ëª©ì  
- Sequence-to-Sequence (Seq2Seq) ëª¨ë¸ì€ ì£¼ë¡œ **í•œ ë„ë©”ì¸ì¸(ì˜ˆ: í•œêµ­ì–´ ë¬¸ì¥)ì—ì„œ ë‹¤ë¥¸ ë„ë©”ì¸**(ì˜ˆ: ì˜ì–´ë¡œ ë²ˆì—­ëœ ë™ì¼í•œ ë¬¸ì¥)ì˜ sequenceë¡œ sequenceë¥¼ ë³€í™˜í•˜ê¸° ìœ„í•œ ëª¨ë¸ì„ ë§í•œë‹¤. 
- "ê¸°ê³„ê°€ ìƒì„±í•œ ë”±ë”±í•œ ë¬¸ì¥ì„ ì¸ê°„ì´ ì“´ ë“¯í•œ ì–¸ì–´ë¡œ ë³€í˜•í•˜ë©´ ì–´ë–¨ê¹Œ?"ë¼ëŠ” ë‹¨ìˆœí•œ ìƒê°ì—ì„œ ì‹œì‘í•˜ê²Œ ëœ í”„ë¡œì íŠ¸

### 1. ë°ì´í„°ì…‹ : VIST

- ë³¸ í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„°ë¡œ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì‚¬ì—ì„œ ì œê³µí•˜ëŠ” VIST(Visual Storytelling Dataset)ì„ ì‚¬ìš©í•¨ 
- VISTëŠ” ì£¼ë¡œ image captioning taskì— ì“°ì´ëŠ” ë°ì´í„°ì…‹ìœ¼ë¡œ, íŠ¹ì • ì´ë²¤íŠ¸ë¡œ ë¬¶ì¸ ìˆœì°¨ì ì¸ ì´ë¯¸ì§€ë“¤ì„ ê°ê° ìº¡ì…˜ ë¬¸ì¥(descriptions for images in isolation, DII)ê³¼ ìˆœì°¨ì ì¸ ìŠ¤í† ë¦¬ ë¬¸ì¥(stories for images in sequence, SIS)ì˜ ìŒìœ¼ë¡œ ì œê³µ
- image captioning taskì— ì“°ì´ëŠ” ê¸°ìˆ ì€ í˜„ ì‹œì ì—ì„œ ë§¤ìš° ë°œì „ë˜ì–´ ìˆê¸°ì— ë°ì´í„°ì…‹ ë˜í•œ ì‰½ê²Œ êµ¬í•  ìˆ˜ ìˆì—ˆìŒ 
- [[Code]](https://github.com/woodongk/story-blender/blob/master/1.%20VIST_data%20preprocessing.ipynb)

### 2. seq2seq ëª¨ë¸



### Reference
- [Kim, Y. (2014). Convolutional neural networks for sentence classification.](https://arxiv.org/abs/1408.5882)
- [CNN in keras with pretrained word2vec weights | Kaggle](https://www.kaggle.com/marijakekic/cnn-in-keras-with-pretrained-word2vec-weights)
- [Using pre-trained word embeddings in a Keras model](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)
- [Implementing a CNN for Text Classification in TensorFlow â€“ WildML](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)



